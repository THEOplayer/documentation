"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([["23626"],{519052(e,t,i){i.r(t),i.d(t,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>n,metadata:()=>s,toc:()=>l});var s=i(21386),r=i(474848),a=i(28453);let n={title:"Getting Started with Subscribing"},c,o={},l=[{value:"1. Import the SDK",id:"1-import-the-sdk",level:2},{value:"2. Configure the audio session for playback.",id:"2-configure-the-audio-session-for-playback",level:2},{value:"3. Create a subscriber",id:"3-create-a-subscriber",level:2},{value:"4. Setup your credentials",id:"4-setup-your-credentials",level:2},{value:"5. Subscribe to a stream",id:"5-subscribe-to-a-stream",level:2},{value:"5.1. Connect to the Millicast service",id:"51-connect-to-the-millicast-service",level:3},{value:"5.2. Subscribe with the preferences",id:"52-subscribe-with-the-preferences",level:3},{value:"6. Manage broadcast events",id:"6-manage-broadcast-events",level:2},{value:"6.1. Receive Audio and Video tracks",id:"61-receive-audio-and-video-tracks",level:3},{value:"6.2. Listen to active/inactive state of tracks",id:"62-listen-to-activeinactive-state-of-tracks",level:3},{value:"6.3. Receive layer information",id:"63-receive-layer-information",level:3},{value:"7. Listen to Websocket and Peer connection state changes",id:"7-listen-to-websocket-and-peer-connection-state-changes",level:2},{value:"8. Render video on the UI",id:"8-render-video-on-the-ui",level:2},{value:"9. Collecting RTC statistics",id:"9-collecting-rtc-statistics",level:2},{value:"10. Error handling",id:"10-error-handling",level:2},{value:"11. Unsubscribe the session",id:"11-unsubscribe-the-session",level:2}];function d(e){let t={a:"a",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.p,{children:"Follow these steps to add the subscribing capability to your application."}),"\n",(0,r.jsx)(t.h2,{id:"1-import-the-sdk",children:"1. Import the SDK"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"import MillicastSDK\n"})}),"\n",(0,r.jsx)(t.h2,{id:"2-configure-the-audio-session-for-playback",children:"2. Configure the audio session for playback."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"let session = AVAudioSession.sharedInstance()\ntry session.setCategory(\n    .playback,\n    mode: .videoChat,\n    options: [.mixWithOthers, .allowBluetooth, .allowBluetoothA2DP]\n)\ntry session.setActive(true)\n"})}),"\n",(0,r.jsx)(t.h2,{id:"3-create-a-subscriber",children:"3. Create a subscriber"}),"\n",(0,r.jsxs)(t.p,{children:["Create a subscriber of type ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber",children:"MCSubscriber"}),"."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"let subscriber = MCSubscriber()\n"})}),"\n",(0,r.jsxs)(t.p,{children:["Optionally implement the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriberdelegate",children:"MCSubscriberDelegate"})," to receive callbacks. Set this delegate during the initialization of ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber",children:"MCSubscriber"}),". Ensure to keep the delegate alive throughout the lifetime of the subscriber, since it does not retain its reference."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"let subscriberDelegate = YourSubscriberDelegate() // where the `YourSubscriberDelegate` is a type that you implement, that conforms to `MCSubscriberDelegate`\nlet subscriber = MCSubscriber(delegate: subscriberDelegate)\n"})}),"\n",(0,r.jsx)(t.h2,{id:"4-setup-your-credentials",children:"4. Setup your credentials"}),"\n",(0,r.jsxs)(t.p,{children:["Get your ",(0,r.jsx)(t.strong,{children:"stream name"})," and ",(0,r.jsx)(t.strong,{children:"stream ID"})," from the dashboard and set them up in the SDK using the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/setcredentials(_:completionhandler:)",children:"setCredentials"})," method."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:'let credentials = MCSubscriberCredentials()\ncredentials.streamName =  "STREAM_NAME"; // The name of the stream you want to subscribe to\ncredentials.accountId = "ACCOUNT_ID"; // The ID of your Dolby.io Real-time Streaming account\ncredentials.apiUrl = "https://director.millicast.com/api/director/subscribe"; // The subscribe API URL\n\ntry await subscriber.setCredentials(credentials)\n'})}),"\n",(0,r.jsx)(t.h2,{id:"5-subscribe-to-a-stream",children:"5. Subscribe to a stream"}),"\n",(0,r.jsx)(t.p,{children:"Subscribing a stream includes two steps."}),"\n",(0,r.jsx)(t.h3,{id:"51-connect-to-the-millicast-service",children:"5.1. Connect to the Millicast service"}),"\n",(0,r.jsxs)(t.p,{children:["Define your connection preferences and ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcclient/connect(completionhandler:)",children:"connect"})," to the Millicast platform."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"let connectionOptions = MCConnectionOptions()\n// Set to `true` if you would like the SDK to reconnect to stream on a connection error; for example - when the network is lost and later restored.\nconnectionOptions.autoReconnect = true\n\ntry await subscriber.connect(with: connectionOptions)\n"})}),"\n",(0,r.jsx)(t.h3,{id:"52-subscribe-with-the-preferences",children:"5.2. Subscribe with the preferences"}),"\n",(0,r.jsxs)(t.p,{children:["Call the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/subscribe(completionhandler:)",children:"subscribe(with:)"})," method passing your preferred subscribe options."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:'let subscriberOptions = MCClientOptions()\n// The main source that will be received by the default media stream\nsubscriberOptions.pinnedSourceId = "MySource";\n// Enables audio multiplexing and denotes the number of audio tracks to receive\n// as Voice Activity Detection (VAD) multiplexed audio\nsubscriberOptions.multiplexedAudioTrack = 3;\n// Audio streams that should not be included in the multiplex, for\n// example your own audio stream\nsubscriberOptions.excludedSourceId = [ "excluded" ]\n// Delay in milliseconds to configure how frequently would you like to receive the\n// stream statistics\nsubscriberOptions.statsDelayMs = 5000\n\ntry await subscriber.subscribe(with: subscriberOptions)\n'})}),"\n",(0,r.jsxs)(t.p,{children:["Refer ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcclientoptions",children:"MCClientOptions"})," for more subscriber options."]}),"\n",(0,r.jsx)(t.h2,{id:"6-manage-broadcast-events",children:"6. Manage broadcast events"}),"\n",(0,r.jsxs)(t.p,{children:["When broadcast events occur, the SDK emits the appropriate event. There are multiple ways to receive those events, using AsyncStream's or by subscribing to Combine Publisher's. Those events can also be received by conforming to ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriberdelegate",children:"MCSubscriberDelegate"})," delegate methods.\nNote: This listener has to be setup before calling the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/subscribe(completionhandler:)",children:"subscribe(with:)"})," method."]}),"\n",(0,r.jsx)(t.h3,{id:"61-receive-audio-and-video-tracks",children:"6.1. Receive Audio and Video tracks"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrack",children:"MCRTSRemoteTrack"})," is a fundamental entity that enables us to view a stream. It can either be a video track or an audio track."]}),"\n",(0,r.jsxs)(t.p,{children:["Receive newly added tracks by listening to subscriber's ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/rtsremotetrackadded",children:"rtsRemoteTrackAdded()"})," stream.\nNewly added tracks can alternatively be received using ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/rtsremotetrackaddedpublisher",children:"rtsRemoteTrackAddedPublisher"})," or the delegate method ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriberdelegate/subscriber(_:didreceivertsremotetrack:)",children:"subscriber(_:didReceiveRTSRemoteTrack:)"})]}),"\n",(0,r.jsxs)(t.p,{children:["Define variables to store the tracks and renderers.\nImportant: Audio and Video tracks of the same source will have the same ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrack/sourceid",children:"sourceId"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"// `sourceIdToVideoTrackDictionary` is used to retain the video tracks returned by the SDK. This helps setup listeners on track or to enable/disable tracks at a later point in time.\nvar sourceIdToVideoTrackDictionary: [String: MCRTSRemoteVideoTrack] = [:]\n\n// `sourceIdToAudioTrackDictionary` is used to retain the audio tracks returned by the SDK. This helps setup listeners on track or to enable/disable tracks at a later point in time.\nvar sourceIdToAudioTrackDictionary: [String: MCRTSRemoteAudioTrack] = [:]\n\n// `sourceIdToRendererDictionary` is used to retain renderer used to enable a video track. The renderers can later be used to display video views on the user interface.\nvar sourceIdToRendererDictionary: [String: MCRTSRemoteAudioTrack] = [:]\n"})}),"\n",(0,r.jsx)(t.p,{children:"Setup listeners to receive audio and video tracks."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"for await track in subscriber.rtsRemoteTrackAdded() {\n  if let videoTrack = track.asVideo() {\n    // Each video track has a one to one relationship to each renderer.\n    // Multiview scenarios require instantiating multiple renderers, one for each track.\n    let renderer = MCCMSampleBufferVideoRenderer()\n    try await videoTrack.enable(renderer: renderer)\n    // Save the renderer and video track\n    sourceIdToRendererDictionary[videoTrack.sourceId] = renderer\n    sourceIdToVideoTrackDictionary[videoTrack.sourceId] = videoTrack\n  } else if let audioTrack = track.asAudio() {\n    // Enable an audio track.\n    try await audioTrack.enable()\n    sourceIdToVideoTrackDictionary[audioTrack.sourceId] = audioTrack\n  }\n}\n"})}),"\n",(0,r.jsx)(t.p,{children:"(or)"}),"\n",(0,r.jsx)(t.p,{children:"Using the combine publisher:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"subscriber.rtsRemoteTrackAddedPublisher\n  .sink { track in\n    Task {\n      if let videoTrack = track.asVideo() {\n        // Each video track has a one to one relationship to each renderer.\n        // Multiview scenarios require instantiating multiple renderers, one for each track.\n        let renderer = MCCMSampleBufferVideoRenderer()\n        try await videoTrack.enable(renderer: renderer)\n        // Save the renderer and video track\n        sourceIdToRendererDictionary[videoTrack.sourceId] = renderer\n        sourceIdToVideoTrackDictionary[videoTrack.sourceId] = videoTrack\n      } else if let audioTrack = track.asAudio() {\n        // Enable an audio track.\n        try await audioTrack.enable()\n        sourceIdToAudioTrackDictionary[audioTrack.sourceId] = audioTrack\n      }\n    }\n  }\n"})}),"\n",(0,r.jsx)(t.h3,{id:"62-listen-to-activeinactive-state-of-tracks",children:"6.2. Listen to active/inactive state of tracks"}),"\n",(0,r.jsxs)(t.p,{children:["Listen to the active and inactive state of a ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrack",children:"MCRTSRemoteTrack"})," using ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrack/activity",children:"activity()"})," stream.\nAlternatively receive this event using the combine publisher ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrack/activitypublisher",children:"activityPublisher()"})]}),"\n",(0,r.jsxs)(t.p,{children:["If you prefer delegates, conform to [MCRTSRemoteTrackDelegate] of a MCRTSRemoteTrack and the use the delegate methods ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrackdelegate/rtsremotetrackactive(_:)",children:"rtsRemoteTrackActive(_:)"})," and ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrackdelegate/rtsremotetrackinactive(_:)",children:"rtsRemoteTrackInactive(_:)"}),"."]}),"\n",(0,r.jsx)(t.p,{children:"Note: A video track receives video frames only when its enabled."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"for await activity in videoTrack.activity() {\n  switch activity {\n  case .inactive:\n    // Optional.\n    // The SDK automatically restores the state of the track when it transitions to `active` from an `inactive` state.\n    // You can optionally disable the video track when it becomes inactive. This step is optional. This gives you control on when to enable the track when it comes back active.\n    try await videoTrack.disable()\n\n  case .active:\n    // Optional.\n    // If you choose to disable a track when it became inactive, you have to enable the video track back after it is active again.\n    // At any point in time when you wish to start receive video from the track, call -\n    try await videoTrack.enable(renderer: renderer)\n  }\n}\n"})}),"\n",(0,r.jsx)(t.p,{children:"Similarly you can listen to active/inactive events of an audio track as below.\nNote: An audio track plays audio only when its enabled."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"for await activity in audioTrack.activity() {\n  switch activity {\n  case .inactive:\n    // Optional.\n    // The SDK automatically restores the state of the track when it transitions to `active` from an `inactive` state. You can optionally disable the audio track when it becomes inactive, so that the responsibility is on you to enable the track when it becomes active.\n    try await audioTrack.disable()\n\n  case .active:\n    // Optional.\n    // At any point in time where you wish to play audio from the track, call -\n    try await audioTrack.enable()\n  }\n}\n"})}),"\n",(0,r.jsx)(t.h3,{id:"63-receive-layer-information",children:"6.3. Receive layer information"}),"\n",(0,r.jsxs)(t.p,{children:["If your video track has multiple layers(spatial or temporal), use the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrack/layers",children:"layers()"})," event to receive the list of active layers. The combine alternative for this event is ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrack/layerspublisher",children:"layersPublisher()"})]}),"\n",(0,r.jsxs)(t.p,{children:["To receive layers from a delegate method, conform to [MCRTSRemoteTrackDelegate], set the delegate of an MCRTSRemoteTrack and then use the delegate method ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcrtsremotetrackdelegate/rtsremotetrack(_:didupdatelayers:)",children:"rtsRemoteTrack(_:didUpdateLayers:)"}),"."]}),"\n",(0,r.jsx)(t.p,{children:"To select a particular layer, re-enable the track by passing the layer that you would like to select."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"for await layerEvent in videoTrack.layers() {\n    // If your application requires to select a specific layer based on an application logic -\n    // Re-enable the track by passing in the layer that you want to select from the list.\n    let selectedLayer = layerEvent.layers[0]\n    try await videoTrack.enable(renderer: renderer, layer: selectedLayer)\n}\n"})}),"\n",(0,r.jsx)(t.h2,{id:"7-listen-to-websocket-and-peer-connection-state-changes",children:"7. Listen to Websocket and Peer connection state changes"}),"\n",(0,r.jsxs)(t.p,{children:["To monitor the state of the websocket connection of the subscriber, use the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/websocketstate",children:"websocketState()"})]}),"\n",(0,r.jsxs)(t.p,{children:["List of possible states are defined in the enum ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcconnectionstate",children:"MCConnectionState"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"for await state in subscriber.websocketState() {\n  // Log or handle the state change\n}\n"})}),"\n",(0,r.jsxs)(t.p,{children:["To check whether you are subscribed successfully to a stream or to listen to other states of a subscription; use ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/peerconnectionstate",children:"peerConnectionState()"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"for await state in subscriber.peerConnectionState() {\n  // Log or handle the state change\n}\n"})}),"\n",(0,r.jsxs)(t.p,{children:["The delegate method equivalents of these events are defined in ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcdelegate",children:"MCDelegate"})]}),"\n",(0,r.jsxs)(t.p,{children:["See ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcdelegate/client(_:didreceivertcpeerconnectionstate:)",children:"client(_:didReceiveRTCPeerConnectionState:)"})," and ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcdelegate/client(_:didreceivewebsocketconnectionstate:)",children:"client(_:didReceiveWebsocketConnectionState:)"})]}),"\n",(0,r.jsx)(t.h2,{id:"8-render-video-on-the-ui",children:"8. Render video on the UI"}),"\n",(0,r.jsxs)(t.p,{children:["The SDK provides SwiftUI Views for rendering a video track. Use ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcvideoswiftuiview",children:"MCVideoSwiftUIView"})," as in the example below:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"struct VideoView: View {\n  private let renderer: MCCMSampleBufferVideoRenderer\n\n  // Important: The renderer passed in for display should be the one that is used to enable a video track.\n  init(renderer: MCCMSampleBufferVideoRenderer) {\n    self.renderer = renderer\n  }\n\n  var body: some View {\n    MCVideoSwiftUIView(renderer: .sampleBuffer(renderer))\n  }\n}\n"})}),"\n",(0,r.jsxs)(t.p,{children:["If your application uses UIKit; use ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcacceleratedvideouiview",children:"MCAcceleratedVideoUIView"})," or ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsamplebuffervideouiview",children:"MCSampleBufferVideoUIView"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"let renderer = MCAcceleratedVideoRenderer()\nlet videoView = MCAcceleratedVideoUIView(frame: view.bounds, renderer: renderer)\nview.addSubview(videoView)\n"})}),"\n",(0,r.jsx)(t.h2,{id:"9-collecting-rtc-statistics",children:"9. Collecting RTC statistics"}),"\n",(0,r.jsxs)(t.p,{children:["You can periodically collect the WebRTC peer connection statistics if you enable them through the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcclient/enablestats(_:completionhandler:)",children:"enableStats"})," method of the subscriber. After enabling the statistics, you will get a report every second through the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/statsreport",children:"statsReport()"})," async stream or the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/statsreportpublisher",children:"statsReportPublisher"})," publisher."]}),"\n",(0,r.jsxs)(t.p,{children:["Alternatively use the delegate method",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcdelegate/client(_:didreceivestatsreport:)",children:"client(_:didreceivestatsreport:)"})]}),"\n",(0,r.jsxs)(t.p,{children:["The identifiers and way to browse the stats are following the ",(0,r.jsx)(t.a,{href:"https://www.w3.org/TR/webrtc-stats/",children:"RTC specification"}),".\nThe report contains the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcstatsreport",children:"MCStatsReport"})," object, which is a collection of several ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcstats",children:"MCStats"})," objects. They all have a specific type, whether it is inbound, outbound, codec, or media. Inbound is the statistics of incoming transport for the viewer and outbound is a type of outgoing statistics for the publisher."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"await subscriber.enableStats(true)\n\nfor await statsReport in subscriber.statsReport() {\n    // Parse the stats report for logging or display on to the user interface\n}\n"})}),"\n",(0,r.jsx)(t.h2,{id:"10-error-handling",children:"10. Error handling"}),"\n",(0,r.jsxs)(t.p,{children:["To listen to the http errors emitted by the subscriber instance, use the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/httperror",children:"httpError()"})," or it's equivalent combine publisher - ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/httperrorpublisher",children:"httpErrorPublisher()"})]}),"\n",(0,r.jsxs)(t.p,{children:["The emitted error will be of type ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mchttpconnectionerror",children:"MCHttpConnectionError"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"for await error in subscriber.httpError() {\n  // Handle http error\n}\n"})}),"\n",(0,r.jsx)(t.p,{children:"(or)"}),"\n",(0,r.jsx)(t.p,{children:"Using the combine publisher:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"subscriber.httpErrorPublisher()\n  .sink { error in\n      // Handle http error\n  }\n"})}),"\n",(0,r.jsxs)(t.p,{children:["To listen to the signalling errors emitted by the subscriber or publisher instance, use the ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/signalingerror",children:"signalingError()"})," or it's equivalent combine publisher - ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/signalingerrorpublisher",children:"signalingErrorPublisher()"})]}),"\n",(0,r.jsxs)(t.p,{children:["The emitted error will be of type ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsignalingerror",children:"MCSignalingError"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"for await error in subscriber.signalingError() {\n  // Handle signalling error\n}\n"})}),"\n",(0,r.jsx)(t.p,{children:"(or)"}),"\n",(0,r.jsx)(t.p,{children:"Using the combine publisher:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"subscriber.signalingErrorPublisher()\n  .sink { error in\n  // Handle signalling error\n  }\n"})}),"\n",(0,r.jsxs)(t.p,{children:["The delegate methods to receive http and signalling errors are ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcdelegate/client(_:didreceivehttpconnectionerror:)",children:"client(_:didreceivehttpconnectionerror:)"})," and ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcdelegate/client(_:didreceivesignalingerror:)",children:"client(_:didreceivesignalingerror:)"})]}),"\n",(0,r.jsx)(t.h2,{id:"11-unsubscribe-the-session",children:"11. Unsubscribe the session"}),"\n",(0,r.jsxs)(t.p,{children:["And finally, when you have finished viewing the stream, stop the subscription by calling ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcsubscriber/unsubscribe(completionhandler:)",children:"unsubscribe()"})," which tell the streaming server that the subscriber is no longer interested in receiving audio and video content. Then disconnect the websocket connection with the server by calling ",(0,r.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/apple/documentation/millicastsdk/mcclient/disconnect(completionhandler:)",children:"disconnect()"})," method."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-swift",children:"try await subscriber.unsubscribe()\ntry await subscriber.disconnect()\n\n// Clear the stored tracks and renderers\nsourceIdToVideoTrackDictionary.removeAll()\nsourceIdToAudioTrackDictionary.removeAll()\nsourceIdToRendererDictionary.removeAll()\n"})})]})}function h(e={}){let{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453(e,t,i){i.d(t,{R:()=>n,x:()=>c});var s=i(296540);let r={},a=s.createContext(r);function n(e){let t=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:n(e.components),s.createElement(a.Provider,{value:t},e.children)}},21386(e){e.exports=JSON.parse('{"id":"playback/players-sdks/ios/sdk/getting-started-with-subscribing","title":"Getting Started with Subscribing","description":"Follow these steps to add the subscribing capability to your application.","source":"@site/millicast/playback/players-sdks/ios/sdk/getting-started-with-subscribing.md","sourceDirName":"playback/players-sdks/ios/sdk","slug":"/playback/players-sdks/ios/sdk/getting-started-with-subscribing","permalink":"/documentation/pr-preview/pr-514/millicast/playback/players-sdks/ios/sdk/getting-started-with-subscribing","draft":false,"unlisted":false,"editUrl":"https://github.com/THEOplayer/documentation/blob/-/millicast/playback/players-sdks/ios/sdk/getting-started-with-subscribing.md","tags":[],"version":"current","frontMatter":{"title":"Getting Started with Subscribing"},"sidebar":"millicast","previous":{"title":"Getting Started with Publishing","permalink":"/documentation/pr-preview/pr-514/millicast/playback/players-sdks/ios/sdk/getting-started-with-publishing"},"next":{"title":"How-to Add Picture in Picture","permalink":"/documentation/pr-preview/pr-514/millicast/playback/players-sdks/ios/sdk/how-to-add-picture-in-picture"}}')}}]);
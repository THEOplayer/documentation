"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([["45965"],{304272:function(e,t,i){i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>n,toc:()=>c});var n=i(393750),a=i(785893),s=i(250065);let o={title:"Getting Started with Publishing"},r=void 0,l={},c=[{value:"1. Add SDK as Gradle Dependency",id:"1-add-sdk-as-gradle-dependency",level:2},{value:"2. Initialize the SDK",id:"2-initialize-the-sdk",level:2},{value:"3. Capture audio and video",id:"3-capture-audio-and-video",level:2},{value:"4. Publish a stream",id:"4-publish-a-stream",level:2},{value:"4.1 Instantiate a publisher",id:"41-instantiate-a-publisher",level:3},{value:"4.2 Set publisher credentials",id:"42-set-publisher-credentials",level:3},{value:"4.3 Add video and audio tracks to the publisher",id:"43-add-video-and-audio-tracks-to-the-publisher",level:3},{value:"4.4 Configure publishing options",id:"44-configure-publishing-options",level:3},{value:"4.5 Publish your stream",id:"45-publish-your-stream",level:3},{value:"5. Observe state changes",id:"5-observe-state-changes",level:2},{value:"5.1 Connection state to the Millicast service",id:"51-connection-state-to-the-millicast-service",level:3},{value:"5.2 Viewers of your stream",id:"52-viewers-of-your-stream",level:3},{value:"6. Collect WebRTC statistics",id:"6-collect-webrtc-statistics",level:2},{value:"7. Disable automatic reconnection",id:"7-disable-automatic-reconnection",level:2},{value:"8. Error handling",id:"8-error-handling",level:2},{value:"9. Close the stream",id:"9-close-the-stream",level:2}];function d(e){let t={a:"a",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.p,{children:"Follow these steps to add the publishing capability to your application."}),"\n",(0,a.jsx)(t.h2,{id:"1-add-sdk-as-gradle-dependency",children:"1. Add SDK as Gradle Dependency"}),"\n",(0,a.jsxs)(t.p,{children:["You can get the SDK library from ",(0,a.jsx)(t.a,{href:"https://central.sonatype.com/artifact/com.millicast/millicast-sdk-android",children:"MavenCentral"}),". If you haven't already, add the following to your gradle dependencies."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:'implementation("com.millicast:millicast-sdk-android:2.0.0")\n'})}),"\n",(0,a.jsx)(t.h2,{id:"2-initialize-the-sdk",children:"2. Initialize the SDK"}),"\n",(0,a.jsxs)(t.p,{children:["Call the ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-core/initialize.html",children:"initialize"})," method to initialize the SDK. This needs to be done only once at the start of the App."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"import android.app.Application\nimport com.millicast.Core\n\nclass MainApplication : Application() {\n  override fun onCreate() {\n    super.onCreate()\n    Core.initialize()\n  }\n}\n"})}),"\n",(0,a.jsx)(t.h2,{id:"3-capture-audio-and-video",children:"3. Capture audio and video"}),"\n",(0,a.jsxs)(t.p,{children:["To capture media, get an array of available ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-media/index.html",children:"audio and video sources"})," and choose the preferred sources from the list. After you start capturing audio and video, the SDK will return an audio and video track that you can add to the publisher later."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:'// Get the first available microphone\nval audioSource = Media.audioSources<MicrophoneAudioSource>().first()\n\nval audioTrack = try {\n    audioSource.startCapture()\n} catch (e: Throwable) {\n    // In the case of a problem when starting the audio capture try checking your permissions\n}\n\n// Get the first camera source\nval videoSource = Media.videoSources<CameraVideoSource>().first()\n\n// Get capabilities of the available video sources, such as width, height, and frame rate\nval capabilities = videoSource.capabilities\n\n// Set the preferred capability; not setting any capability object results in setting the first one from the list\nvideoSource.setCapability(capabilities.first())\n\n// Start capturing video\nval videoTrack = try {\n    videoSource.startCapture()\n} catch (e: RuntimeException) {\n    // In the case of a problem when starting the video capture\n    // check the camera permissions or exclusive access from another application\n}\n\n// Handle switching between cameras\nvideoSource.switchCamera(object: SwitchCameraHandler {\n  override fun onCameraSwitchDone(p0: Boolean) {\n    TODO("Not yet implemented")\n  }\n\n  override fun onCameraSwitchError(reason: String?) {\n    TODO("Not yet implemented")\n  }\n})\n\n// Replace width, height, and fps with your own values\nvideoSource.changeCaptureFormat(width, height, fps)\n'})}),"\n",(0,a.jsx)(t.h2,{id:"4-publish-a-stream",children:"4. Publish a stream"}),"\n",(0,a.jsx)(t.h3,{id:"41-instantiate-a-publisher",children:"4.1 Instantiate a publisher"}),"\n",(0,a.jsxs)(t.p,{children:["Create a ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-core/create-publisher.html",children:"publisher object"})]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"val publisher = Core.createPublisher()\n"})}),"\n",(0,a.jsx)(t.h3,{id:"42-set-publisher-credentials",children:"4.2 Set publisher credentials"}),"\n",(0,a.jsxs)(t.p,{children:["Make sure to use the publisher's methods in a coroutine context. Then, create a stream in your Dolby.io developer dashboard or using the Dolby.io Streaming REST API and ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-publisher/set-credentials.html",children:"set your credentials"}),". Collecting the ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-publisher/current-state.html",children:"state"})," of the publisher object from its StateFlow is important for handling errors and knowing if the SDK is ready for the ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-publisher/publish.html",children:"publish"})," call to happen."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:'// Helper for later usage\nfun <T> CoroutineScope.safeLaunch(\n	onError: (suspend CoroutineScope.(err: Throwable) -> T)? = null,\n    block: suspend CoroutineScope.() -> T\n  ) = launch {\n    try {\n      block()\n    } catch (err: Throwable) {\n      onError?.invoke(this, err)\n    }\n  }\n\n  // Most of the publisher\'s methods needs to be in a coroutine context,\n  // such as viewModelScope or ServiceJob\n  val coroutineScope = CoroutineScope(Dispatchers.IO)\n\n  // In this sample, we deroute the scope to collect every new publisher\'s state\n  // For instance, in a jetpack compose implementation it could be:\n  //\n  // @Composable\n  // fun MyLoadingScreen(publisher: Publisher) {\n  //   val state by publisher.state.collectAsState(null)\n  //\n  //   state?.let {\n  //     when(it.connectionState) {\n  //       ConnectionState.Connected -> ...\n  //       else -> ...\n  //     }\n  //   }\n  // }\n  coroutineScope.async {\n    publisher.state.collect { newPublisherState ->\n      Log.d("SAMPLE", "having new State ${newPublisherState}")\n    }\n  }\n\n  // Get the credentials structure from your publisher instance, fill it in, and set the modified credentials\n  coroutineScope.safeLaunch {\n    val credential = Credential(\n      // Set the streamName, token, and API URL\n      streamName = "myStreamName",\n      token = "aefea56153765316754fe",\n      apiUrl = "https://director.millicast.com/api/director/publish"\n    )\n\n    publisher.setCredentials(credential)\n  }\n'})}),"\n",(0,a.jsx)(t.h3,{id:"43-add-video-and-audio-tracks-to-the-publisher",children:"4.3 Add video and audio tracks to the publisher"}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-publisher/add-track.html",children:"Add"})," the audio and video track that you created earlier when you started capturing media."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"// Use the previous publisher and coroutine scope\ncoroutineScope.safeLaunch {\n  // Previously created tracks:\n\n  publisher.addTrack(videoTrack);\n  publisher.addTrack(audioTrack);\n}\n"})}),"\n",(0,a.jsx)(t.h3,{id:"44-configure-publishing-options",children:"4.4 Configure publishing options"}),"\n",(0,a.jsx)(t.p,{children:"Configure publishing options in the publisher, such as selecting the audio and video codecs or enabling multi-source on the publisher."}),"\n",(0,a.jsxs)(t.p,{children:["Get a list of the ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-media/index.html",children:"available codecs"})," and ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast.publishers/-option/index.html",children:"set"})," the codecs that you want to use. By default, the SDK uses VP8 as the video codec and Opus as the audio codec."]}),"\n",(0,a.jsx)(t.p,{children:"Additionally, to publish several sources from the same application, create a publisher instance for each source. We recommend enabling discontinuous transmission that detects audio input and sends audio only when it is detected."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:'// Use the previous publisher and coroutine scope\n\ncoroutineScope.safeLaunch {\n  val videoCodecs = Media.supportedVideoCodecs\n  val audioCodecs = Media.supportedAudioCodecs\n\n  publisher.connect()\n}\n\n// Call publish after reaching the PublisherConnectionState.Connected state\ncoroutineScope.safeLaunch {\n  publisher.publish(\n    Option(\n      // Choose the preferred codecs\n      videoCodec = videoCodecs.first(),\n      audioCodec = audioCodecs.first(),\n      // If you want to support multi-source, set a source ID of the publisher\n      // To publish several sources from the same application, create a publisher instance for each source\n      sourceId = "sourceId",\n      // Set dtx to true for discontinuous audio transmission, i.e. only send audio when a user\'s voice is detected\n      dtx = true,\n      // Enable stereo\n      stereo = true\n    )\n  )\n}\n'})}),"\n",(0,a.jsx)(t.h3,{id:"45-publish-your-stream",children:"4.5 Publish your stream"}),"\n",(0,a.jsx)(t.p,{children:"Connect to the Millicast service and publish your streams."}),"\n",(0,a.jsxs)(t.p,{children:["Use the ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-client/connect.html",children:"connect"})," method to authenticate and access Dolby.io Real-time Streaming through the Director API. Successful authentication results in opening a WebSocket connection that allows using the Dolby.io Real-time Streaming server and receiving a StateFlow update to ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-publisher/current-state.html",children:"state"})," as PublisherConnectionState.Connected."]}),"\n",(0,a.jsxs)(t.p,{children:["Only after a successful connection, use the ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-publisher/publish.html?query=suspend%20fun%20publish():%20Boolean",children:"publish"})," method to start publishing the stream. Once the publisher starts sending media, the SDK will update ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-publisher/current-state.html",children:"state"})," to PublisherConnectionState.Started."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"// Call publish after reaching the PublisherConnectionState.Connected state\ncoroutineScope.safeLaunch {\n  publisher.state.map { it.connectionState }.distinctUntilChanged().collect {\n    if (it == PublisherConnectionState.Connected) {\n      // Set options as defined earlier\n      publisher.publish(options)\n    }\n  }\n}\n"})}),"\n",(0,a.jsx)(t.h2,{id:"5-observe-state-changes",children:"5. Observe state changes"}),"\n",(0,a.jsx)(t.p,{children:"There are different publishers that emit events informing you of the state of your stream. Please note, the listeners should be setup before you start publishing so you receive all the events from a publisher."}),"\n",(0,a.jsx)(t.h3,{id:"51-connection-state-to-the-millicast-service",children:"5.1 Connection state to the Millicast service"}),"\n",(0,a.jsx)(t.p,{children:"To monitor the state of the connection to the publisher and the state of the publishing, use the following code"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"launch {\n  publisher.state.map { it.connectionState }.distinctUntilChanged().collect { state ->\n    when(state) {\n      PublisherConnectionState.Connected -> {}\n      PublisherConnectionState.Connecting -> {}\n      PublisherConnectionState.Disconnected -> {}\n      PublisherConnectionState.DisconnectedError -> {}\n      PublisherConnectionState.Disconnecting -> {}\n      is PublisherConnectionState.Error -> {}\n      PublisherConnectionState.Started -> {}\n      PublisherConnectionState.Stopped -> {}\n    }\n  }\n}\n"})}),"\n",(0,a.jsx)(t.h3,{id:"52-viewers-of-your-stream",children:"5.2 Viewers of your stream"}),"\n",(0,a.jsx)(t.p,{children:"Listen to the viewer activity events of your stream using"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:'launch {\n  publisher.state.map {it.active}.distinctUntilChanged().collect { viewersActive ->\n    if(viewersActive) {\n      Log.d("Event:", "Viewers active")\n    } else {\n      Log.d("Event:", "No Viewers active")\n    }\n  }\n}\n'})}),"\n",(0,a.jsx)(t.p,{children:"Number of viewers viewing your stream in a given time is yet another vital aspect for you as a publisher. To listen to viewer count updates, use"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:'launch {\n  publisher.state.map {it.viewers}.distinctUntilChanged().collect { viewerCount ->\n    Log.d("Event:", "Viewer count is $viewerCount")\n  }\n}\n'})}),"\n",(0,a.jsx)(t.h2,{id:"6-collect-webrtc-statistics",children:"6. Collect WebRTC statistics"}),"\n",(0,a.jsxs)(t.p,{children:["Set the ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-client/enable-stats.html",children:"enableStats"})," method to true to collect statistics.\nYou can periodically collect the WebRTC peer connection statistics if you enable them through the enableStats method of the publisher. After enabling the statistics, you will get a report every second through the ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast.clients/-listener/on-stats-report.html?query=abstract%20fun%20onStatsReport(report:%20RtsReport)",children:"onStatsReport"})," callback in the listener object. The identifiers and way to browse the stats are following the RTC specification. The report contains the RTSReport object, which is a collection of several Stats objects. They all have a specific type, whether it is inbound, outbound, codec, or media. Inbound is the statistics of incoming transport for the viewer and outbound is a type of outgoing statistics for the publisher."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"publisher.rtcStatsReport.collect { report ->\n  // Parse the stats report for logging or display on to the user interface\n}\n"})}),"\n",(0,a.jsx)(t.h2,{id:"7-disable-automatic-reconnection",children:"7. Disable automatic reconnection"}),"\n",(0,a.jsxs)(t.p,{children:["By default, the publisher and subscriber attempt to reconnect automatically in case of network errors. To disable auto reconnection in ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast.clients/-connection-options/index.html",children:"ConnectionOptions"}),", use the following code:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"val connectionOption = ConnectionOptions(autoReconnect = false)\npublisher.connect(connectionOption)\n"})}),"\n",(0,a.jsx)(t.h2,{id:"8-error-handling",children:"8. Error handling"}),"\n",(0,a.jsx)(t.p,{children:"To listen to the errors emitted by the publisher, listen to the connectionState of the publisher.state as described in section 5.1. In addition to that there are additional two state events that can be monitored for errors. Publisher also provides notification for any signalling error in publisher.signalingError."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"publisher.state.map { it.peerConnectionState }.distinctUntilChanged().collect {}\npublisher.state.map { it.websocketConnectionState }.distinctUntilChanged().collect {}\n\npublisher.signalingError.distinctUntilChanged().collect {}\n"})}),"\n",(0,a.jsx)(t.h2,{id:"9-close-the-stream",children:"9. Close the stream"}),"\n",(0,a.jsxs)(t.p,{children:["To close the publishing stream and handle proper cleanup of resources, first ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-publisher/unpublish.html",children:"unpublish"})," and ",(0,a.jsx)(t.a,{href:"https://millicast.github.io/doc/latest/android/android/com.millicast/-client/disconnect.html",children:"disconnect"})," the publisher, then close and release the publishing sources. Note that unlike publish and connect, these steps don't have to wait for an updated state before being called."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-kotlin",children:"// With the same coroutine scope\ncoroutineScope.safeLaunch {\n  // disconnect the publisher\n  publisher.unpublish()\n  publisher.disconnect()\n  // stop the source captures\n  audioSource.stopCapture()\n  videoSource.stopCapture()\n  // release the sources\n  audioSource.release()\n  videoSource.release()\n}\n"})})]})}function h(e={}){let{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},250065:function(e,t,i){i.d(t,{Z:()=>r,a:()=>o});var n=i(667294);let a={},s=n.createContext(a);function o(e){let t=n.useContext(s);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),n.createElement(s.Provider,{value:t},e.children)}},393750:function(e){e.exports=JSON.parse('{"id":"playback/players-sdks/android/sdk/getting-started-with-publishing","title":"Getting Started with Publishing","description":"Follow these steps to add the publishing capability to your application.","source":"@site/millicast/playback/players-sdks/android/sdk/getting-started-with-publishing.md","sourceDirName":"playback/players-sdks/android/sdk","slug":"/playback/players-sdks/android/sdk/getting-started-with-publishing","permalink":"/documentation/pr-preview/pr-383/millicast/playback/players-sdks/android/sdk/getting-started-with-publishing","draft":false,"unlisted":false,"editUrl":"https://github.com/THEOplayer/documentation/blob/-/millicast/playback/players-sdks/android/sdk/getting-started-with-publishing.md","tags":[],"version":"current","frontMatter":{"title":"Getting Started with Publishing"},"sidebar":"millicast","previous":{"title":"Millicast SDK","permalink":"/documentation/pr-preview/pr-383/millicast/playback/players-sdks/android/sdk/"},"next":{"title":"Getting Started with Subscribing","permalink":"/documentation/pr-preview/pr-383/millicast/playback/players-sdks/android/sdk/getting-started-with-subscribing"}}')}}]);